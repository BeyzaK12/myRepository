{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Beyza_Kurt_HW_part2_CENG3526","provenance":[{"file_id":"17oBU3YFPpXbxI-cUSIyw8M3yFVe-PI0s","timestamp":1589049485088}],"collapsed_sections":[],"authorship_tag":"ABX9TyNQu6dnt8NDHdgChXMbPntg"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"L1Voe7YT_PJX","colab_type":"code","colab":{}},"source":["import io, os\n","import re as re\n","import zipfile as zipfile\n","import math\n","import numpy as np\n","import random\n","from operator import itemgetter\n","import itertools\n","import scipy.spatial.distance\n","from sklearn.metrics import accuracy_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iYaKz15qZonk","colab_type":"code","outputId":"a2e312fa-487a-4497-e2c6-82330a0ca436","executionInfo":{"status":"ok","timestamp":1589244353827,"user_tz":-180,"elapsed":20446,"user":{"displayName":"WhineyB","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_Vi2WUiksXxY70zz29ccNDzRabkMQHNJW4rgF0A=s64","userId":"14308996959334696623"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iiqGFx08yX2X","colab_type":"code","colab":{}},"source":["stop_words = ['a', 'acaba', 'altı', 'ama', 'ancak', 'artık', 'asla', 'aslında', 'az', 'b', 'bana', 'bazen', 'bazı', 'bazıları', 'bazısı', 'belki', 'ben', 'beni', 'benim', 'beş', 'bile', 'bir', 'birçoğu', 'birçok', 'birçokları', 'biri', 'birisi', 'birkaç', 'birkaçı', 'birşey', 'birşeyi', 'biz', 'bize', 'bizi', 'bizim', 'böyle', 'böylece', 'bu', 'buna', 'bunda', 'bundan', 'bunu', 'bunun', 'burada', 'bütün', 'c', 'ç', 'çoğu', 'çoğuna', 'çoğunu', 'çok', 'çünkü', 'd', 'da', 'daha', 'de', 'değil', 'demek', 'diğer', 'diğeri', 'diğerleri', 'diye', 'dokuz', 'dolayı', 'dört', 'e', 'elbette', 'en', 'f', 'fakat', 'falan', 'felan', 'filan', 'g', 'gene', 'gibi', 'ğ', 'h', 'hâlâ', 'hangi', 'hangisi', 'hani', 'hatta', 'hem', 'henüz', 'hep', 'hepsi', 'hepsine', 'hepsini', 'her', 'her biri', 'herkes', 'herkese', 'herkesi', 'hiç', 'hiç kimse', 'hiçbiri', 'hiçbirine', 'hiçbirini', 'ı', 'i', 'için', 'içinde', 'iki', 'ile', 'ise', 'işte', 'j', 'k', 'kaç', 'kadar', 'kendi', 'kendine', 'kendini', 'ki', 'kim', 'kime', 'kimi', 'kimin', 'kimisi', 'l', 'm', 'madem', 'mı', 'mı', 'mi', 'mu', 'mu', 'mü', 'mü', 'n', 'nasıl', 'ne', 'ne kadar', 'ne zaman', 'neden', 'nedir', 'nerde', 'nerede', 'nereden', 'nereye', 'nesi', 'neyse', 'niçin', 'niye', 'o', 'on', 'ona', 'ondan', 'onlar', 'onlara', 'onlardan', 'onların', 'onların', 'onu', 'onun', 'orada', 'oysa', 'oysaki', 'ö', 'öbürü', 'ön', 'önce', 'ötürü', 'öyle', 'p', 'r', 'rağmen', 's', 'sana', 'sekiz', 'sen', 'senden', 'seni', 'senin', 'siz', 'sizden', 'size', 'sizi', 'sizin', 'son', 'sonra', 'ş', 'şayet', 'şey', 'şeyden', 'şeye', 'şeyi', 'şeyler', 'şimdi', 'şöyle', 'şu', 'şuna', 'şunda', 'şundan', 'şunlar', 'şunu', 'şunun', 't', 'tabi', 'tamam', 'tüm', 'tümü', 'u', 'ü', 'üç', 'üzere', 'v', 'var', 've', 'veya', 'veyahut', 'y', 'ya', 'ya da', 'yani', 'yedi', 'yerine', 'yine', 'yoksa', 'z', 'zaten', 'zira']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mN8iG5JYgzdp","colab_type":"code","colab":{}},"source":["commentsW = {}\n","mytextzip = ''\n","path = '/content/drive/My Drive/film_yorumlari.zip'\n","\n","emotions = {\n","    \"1\": \"pozitif\",\n","    \"2\": \"tarafsiz\",\n","    \"3\": \"negatif\"\n","}\n","\n","with zipfile.ZipFile(path) as z:\n","    for zipinfo in z.infolist():\n","        if zipinfo.filename.endswith('.txt') and re.search('raw_texts', zipinfo.filename):\n","            with z.open(zipinfo) as f:\n","                textfile = io.TextIOWrapper(f, encoding='cp1254', newline='')\n","                for line in textfile:\n","                    if len(line.strip()): mytextzip += line.strip()\n","\n","                filename = str(zipinfo.filename)\n","                parts = filename.split(\"/\")\n","                hash = parts[-2]\n","                for key, emot in emotions.items():\n","                    if hash == emot:\n","                        hash = key\n","                        break\n","                parts = parts[-1].split(\".\")\n","                doc = parts[0]\n","                \n","                commentsW[(doc, hash)] = mytextzip\n","                mytextzip = ''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kmG1dNFRuo4d","colab_type":"code","colab":{}},"source":["def Tokenizer(text, stop):\n","    text = (str(text)).lower()          # normalize\n","    words = re.findall(r'\\w+', text)    # find all words in it\n","\n","    if stop == 1:\n","        #remove stopwords, start last word to avoid index problems in loop\n","        for x in range(len(words)-1, -1, -1):\n","            word = str(words[x])\n","            if word in stop_words:\n","                words.pop(x)\n","            elif word.lower() in stop_words:\n","                words.pop(x)\n","    \n","    return words"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qqny0F0rg2qT","colab_type":"code","colab":{}},"source":["def turner(dictionary):\n","    for key, comment in dictionary.items():\n","        dictionary[key] = Tokenizer(comment, 1)\n","    return dictionary"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5r0UfHZVEHks","colab_type":"code","colab":{}},"source":["commentsW = turner(commentsW)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l3oWMP-IEQme","colab_type":"code","outputId":"616e06a0-4c2a-45fc-c63c-de1dfe07cc84","executionInfo":{"status":"ok","timestamp":1589244354626,"user_tz":-180,"elapsed":21204,"user":{"displayName":"WhineyB","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_Vi2WUiksXxY70zz29ccNDzRabkMQHNJW4rgF0A=s64","userId":"14308996959334696623"}},"colab":{"base_uri":"https://localhost:8080/","height":89}},"source":["i = 0\n","for (doc, emot), words in commentsW.items():\n","    print(doc, emot, words)\n","    if i == 2:\n","        break\n","    i += 1"],"execution_count":8,"outputs":[{"output_type":"stream","text":["1 3 ['senariste', 'lafım', 'rain', 'man', 'filmini', 'taklit', 'ederek', 'senaryo', 'yazılmaz', 'yönetmene', 'lafım', 'filmin', 'sonunda', 'milleti', 'ağlatmak', 'türlü', 'şaklabanlıklara', 'girilmez', 'olarak', 'yağmur', 'sahnesini', 'millet', 'anlamaz', 'bak', 'itfaiye', 'hortumuyla', 'sağlıyorum', 'görün', 'gösterilmez', 'bunları', 'göremeyen', 'izleyicilerde', 'sakın', 'film', 'harika', 'demesin']\n","10 3 ['çıkış', 'zamanı', 'itibariyle', 'hassas', 'dönemden', 'geçtiği', 'ülkemiz', 'film', 'gişe', 'yaptı', 'nsanlar', 'milliyetcilik', 'duygularıyla', 'akın', 'ettiler', 'sinemalara', 'ahım', 'şahım', 'bi', 'film', 'konu', 'yok', 'olaylar', 'arası', 'bağlantı', 'yok', 'görsellik', 'yok', 'sahneler', 'uzundu', 'bari', 'sonu', 'güzel', 'bağlansın', 'umut', 'ettim', 'tam', 'fiyaskoydu']\n","11 3 ['eğer', 'birazcık', 'filmden', 'anlıyorsam', 'film', 'para', 'etmez', 'tam', 'hayal', 'kırıklığı', 'sadece', 'insanların', 'duygularını', 'sömürüp', 'paraları', 'cebe', 'atmak', 'yapılmış', 'bi', 'film', 'filmde', 'tane', 'sahne', 'fragmana', 'koymak', 'yapılmış', 'sanırım', 'gerisi', 'boş', 'sahneler', 'onlarıda', 'uzatmışlar', 'uzatmışlar', 'kesinlikler', 'tavsiye', 'etmiyorum']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dNgbqjLqcfQp","colab_type":"code","colab":{}},"source":["term_frequencies = {}       # { doc: {word: word frequency} }\n","\n","for (doc, emot), words in commentsW.items():\n","    d = {}\n","    temp = []\n","    \n","    #term frequency\n","    for word in words:\n","        if word not in d:\n","            d[word] = 1\n","        else:\n","            d[word] += 1\n","\n","    n = len(d)      # of words in doc\n","    for word, number in d.items():\n","        tf = number / n\n","        temp.append([word, tf])\n","\n","    key = str(doc)+\".\"+str(emot)\n","    term_frequencies[key] = temp"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TUpzETkzEMqG","colab_type":"code","outputId":"86f136db-4f5a-454f-cc92-3187f627f8ad","executionInfo":{"status":"ok","timestamp":1589244354629,"user_tz":-180,"elapsed":21191,"user":{"displayName":"WhineyB","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_Vi2WUiksXxY70zz29ccNDzRabkMQHNJW4rgF0A=s64","userId":"14308996959334696623"}},"colab":{"base_uri":"https://localhost:8080/","height":89}},"source":["i = 0\n","for doc, freq in term_frequencies.items():\n","    print(doc, freq)\n","    if i == 2:\n","        break\n","    i += 1"],"execution_count":10,"outputs":[{"output_type":"stream","text":["1.3 [['senariste', 0.02857142857142857], ['lafım', 0.05714285714285714], ['rain', 0.02857142857142857], ['man', 0.02857142857142857], ['filmini', 0.02857142857142857], ['taklit', 0.02857142857142857], ['ederek', 0.02857142857142857], ['senaryo', 0.02857142857142857], ['yazılmaz', 0.02857142857142857], ['yönetmene', 0.02857142857142857], ['filmin', 0.02857142857142857], ['sonunda', 0.02857142857142857], ['milleti', 0.02857142857142857], ['ağlatmak', 0.02857142857142857], ['türlü', 0.02857142857142857], ['şaklabanlıklara', 0.02857142857142857], ['girilmez', 0.02857142857142857], ['olarak', 0.02857142857142857], ['yağmur', 0.02857142857142857], ['sahnesini', 0.02857142857142857], ['millet', 0.02857142857142857], ['anlamaz', 0.02857142857142857], ['bak', 0.02857142857142857], ['itfaiye', 0.02857142857142857], ['hortumuyla', 0.02857142857142857], ['sağlıyorum', 0.02857142857142857], ['görün', 0.02857142857142857], ['gösterilmez', 0.02857142857142857], ['bunları', 0.02857142857142857], ['göremeyen', 0.02857142857142857], ['izleyicilerde', 0.02857142857142857], ['sakın', 0.02857142857142857], ['film', 0.02857142857142857], ['harika', 0.02857142857142857], ['demesin', 0.02857142857142857]]\n","10.3 [['çıkış', 0.02857142857142857], ['zamanı', 0.02857142857142857], ['itibariyle', 0.02857142857142857], ['hassas', 0.02857142857142857], ['dönemden', 0.02857142857142857], ['geçtiği', 0.02857142857142857], ['ülkemiz', 0.02857142857142857], ['film', 0.05714285714285714], ['gişe', 0.02857142857142857], ['yaptı', 0.02857142857142857], ['nsanlar', 0.02857142857142857], ['milliyetcilik', 0.02857142857142857], ['duygularıyla', 0.02857142857142857], ['akın', 0.02857142857142857], ['ettiler', 0.02857142857142857], ['sinemalara', 0.02857142857142857], ['ahım', 0.02857142857142857], ['şahım', 0.02857142857142857], ['bi', 0.02857142857142857], ['konu', 0.02857142857142857], ['yok', 0.08571428571428572], ['olaylar', 0.02857142857142857], ['arası', 0.02857142857142857], ['bağlantı', 0.02857142857142857], ['görsellik', 0.02857142857142857], ['sahneler', 0.02857142857142857], ['uzundu', 0.02857142857142857], ['bari', 0.02857142857142857], ['sonu', 0.02857142857142857], ['güzel', 0.02857142857142857], ['bağlansın', 0.02857142857142857], ['umut', 0.02857142857142857], ['ettim', 0.02857142857142857], ['tam', 0.02857142857142857], ['fiyaskoydu', 0.02857142857142857]]\n","11.3 [['eğer', 0.030303030303030304], ['birazcık', 0.030303030303030304], ['filmden', 0.030303030303030304], ['anlıyorsam', 0.030303030303030304], ['film', 0.06060606060606061], ['para', 0.030303030303030304], ['etmez', 0.030303030303030304], ['tam', 0.030303030303030304], ['hayal', 0.030303030303030304], ['kırıklığı', 0.030303030303030304], ['sadece', 0.030303030303030304], ['insanların', 0.030303030303030304], ['duygularını', 0.030303030303030304], ['sömürüp', 0.030303030303030304], ['paraları', 0.030303030303030304], ['cebe', 0.030303030303030304], ['atmak', 0.030303030303030304], ['yapılmış', 0.06060606060606061], ['bi', 0.030303030303030304], ['filmde', 0.030303030303030304], ['tane', 0.030303030303030304], ['sahne', 0.030303030303030304], ['fragmana', 0.030303030303030304], ['koymak', 0.030303030303030304], ['sanırım', 0.030303030303030304], ['gerisi', 0.030303030303030304], ['boş', 0.030303030303030304], ['sahneler', 0.030303030303030304], ['onlarıda', 0.030303030303030304], ['uzatmışlar', 0.06060606060606061], ['kesinlikler', 0.030303030303030304], ['tavsiye', 0.030303030303030304], ['etmiyorum', 0.030303030303030304]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h0q0hy5YmacS","colab_type":"code","colab":{}},"source":["idfs = {}            # {word: number} ---> {word: idf}\n","\n","for doc, array in term_frequencies.items():\n","    for word, tf in array:\n","        if word not in idfs:\n","            idfs[word] = 1\n","        else:\n","            idfs[word] += 1\n","\n","doc_total = len(term_frequencies)\n","for word, n in idfs.items():\n","    idf = ((1 + doc_total) / (n+1))\n","    idfs[word] = math.log(idf) + 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jK9uBhSmEEOi","colab_type":"code","outputId":"81fd6b79-c285-4a9b-e474-30b298bc55a4","executionInfo":{"status":"ok","timestamp":1589244354632,"user_tz":-180,"elapsed":21177,"user":{"displayName":"WhineyB","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_Vi2WUiksXxY70zz29ccNDzRabkMQHNJW4rgF0A=s64","userId":"14308996959334696623"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["i = 0\n","for word, freqdocs in idfs.items():\n","    print(word, freqdocs)\n","    if i == 2:\n","        break\n","    i += 1"],"execution_count":12,"outputs":[{"output_type":"stream","text":["senariste 4.970291913552122\n","lafım 4.970291913552122\n","rain 3.8716796248840124\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EGTd9K__06BZ","colab_type":"code","colab":{}},"source":["# TF-IDF = TF * IDF\n","tfidf = {}                      #{doc: {word: tf-idf}}\n","\n","for doc, array in term_frequencies.items():\n","    tfidf[doc] = {}\n","    for word, tf in array:\n","        TfIdf = tf * idfs[word]\n","        tfidf[doc][word] = TfIdf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR6mNBq6EBzS","colab_type":"code","outputId":"ae5a2ea4-157a-4745-c4d0-06add6ff5c0f","executionInfo":{"status":"ok","timestamp":1589244354634,"user_tz":-180,"elapsed":21161,"user":{"displayName":"WhineyB","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_Vi2WUiksXxY70zz29ccNDzRabkMQHNJW4rgF0A=s64","userId":"14308996959334696623"}},"colab":{"base_uri":"https://localhost:8080/","height":89}},"source":["i = 0\n","for doc, ti in tfidf.items():\n","    print(doc, ti)\n","    if i == 2:\n","        break\n","    i += 1"],"execution_count":14,"outputs":[{"output_type":"stream","text":["1.3 {'senariste': 0.1420083403872035, 'lafım': 0.284016680774407, 'rain': 0.11061941785382892, 'man': 0.11061941785382892, 'filmini': 0.13042362301268448, 'taklit': 0.11582860519079903, 'ederek': 0.1420083403872035, 'senaryo': 0.10239993006949231, 'yazılmaz': 0.1420083403872035, 'yönetmene': 0.13042362301268448, 'filmin': 0.06660670239819609, 'sonunda': 0.11061941785382892, 'milleti': 0.1420083403872035, 'ağlatmak': 0.1420083403872035, 'türlü': 0.11582860519079903, 'şaklabanlıklara': 0.1420083403872035, 'girilmez': 0.1420083403872035, 'olarak': 0.07923049532045436, 'yağmur': 0.10239993006949231, 'sahnesini': 0.1420083403872035, 'millet': 0.13042362301268448, 'anlamaz': 0.1420083403872035, 'bak': 0.1420083403872035, 'itfaiye': 0.1420083403872035, 'hortumuyla': 0.1420083403872035, 'sağlıyorum': 0.1420083403872035, 'görün': 0.13042362301268448, 'gösterilmez': 0.1420083403872035, 'bunları': 0.13042362301268448, 'göremeyen': 0.1420083403872035, 'izleyicilerde': 0.1420083403872035, 'sakın': 0.13042362301268448, 'film': 0.04167847070631717, 'harika': 0.10621511271590725, 'demesin': 0.1420083403872035}\n","10.3 {'çıkış': 0.13042362301268448, 'zamanı': 0.1420083403872035, 'itibariyle': 0.12220413522834792, 'hassas': 0.1420083403872035, 'dönemden': 0.1420083403872035, 'geçtiği': 0.1420083403872035, 'ülkemiz': 0.1420083403872035, 'film': 0.08335694141263433, 'gişe': 0.13042362301268448, 'yaptı': 0.1420083403872035, 'nsanlar': 0.12220413522834792, 'milliyetcilik': 0.1420083403872035, 'duygularıyla': 0.1420083403872035, 'akın': 0.13042362301268448, 'ettiler': 0.1420083403872035, 'sinemalara': 0.1420083403872035, 'ahım': 0.1420083403872035, 'şahım': 0.1420083403872035, 'bi': 0.08852827819001514, 'konu': 0.09081521269497334, 'yok': 0.24259077857621578, 'olaylar': 0.1420083403872035, 'arası': 0.13042362301268448, 'bağlantı': 0.1420083403872035, 'görsellik': 0.13042362301268448, 'sahneler': 0.11582860519079903, 'uzundu': 0.1420083403872035, 'bari': 0.13042362301268448, 'sonu': 0.11061941785382892, 'güzel': 0.06872407303115957, 'bağlansın': 0.1420083403872035, 'umut': 0.1420083403872035, 'ettim': 0.13042362301268448, 'tam': 0.08641090755705166, 'fiyaskoydu': 0.1420083403872035}\n","11.3 {'eğer': 0.1296104464543084, 'birazcık': 0.15061490647127643, 'filmden': 0.10860598643734035, 'anlıyorsam': 0.15061490647127643, 'film': 0.0884088772558243, 'para': 0.1126523922744471, 'etmez': 0.13832808501345326, 'tam': 0.09164793225747905, 'hayal': 0.11732362499648523, 'kırıklığı': 0.1296104464543084, 'sadece': 0.12284852065690807, 'insanların': 0.12284852065690807, 'duygularını': 0.15061490647127643, 'sömürüp': 0.15061490647127643, 'paraları': 0.15061490647127643, 'cebe': 0.15061490647127643, 'atmak': 0.15061490647127643, 'yapılmış': 0.2172119728746807, 'bi': 0.0938936283833494, 'filmde': 0.0938936283833494, 'tane': 0.12284852065690807, 'sahne': 0.1296104464543084, 'fragmana': 0.15061490647127643, 'koymak': 0.15061490647127643, 'sanırım': 0.12284852065690807, 'gerisi': 0.15061490647127643, 'boş': 0.13832808501345326, 'sahneler': 0.12284852065690807, 'onlarıda': 0.15061490647127643, 'uzatmışlar': 0.30122981294255285, 'kesinlikler': 0.15061490647127643, 'tavsiye': 0.10184406063994005, 'etmiyorum': 0.13832808501345326}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I-1IlRwz4MI8","colab_type":"code","colab":{}},"source":["vectorS = []\n","dictionary = {}\n","\n","i = 0\n","for doc, tis in tfidf.items():\n","    vectorS.append([])\n","    # doc = \"1.11\"\n","    # tis = {'time': 0.009378893551214249, 'year': 0.02088227471955536,...}\n","    # doc = \"1.12\"\n","    # tis = {'time': 0.010133140235402807, 'year': 0.011280809245354205,...}\n","    for word, df in idfs.items():\n","        # word = \"doubt\"\n","        if word not in tis:\n","            vectorS[i].append(0)\n","        else:\n","            ti = tis[word]\n","            vectorS[i].append(ti)\n","    emot = doc.split(\".\")\n","    emot = emot[1]\n","    if emot not in dictionary:\n","        dictionary[emot] = []\n","    dictionary[emot].append(vectorS[i])\n","    i += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-aCNtmPBOMiJ","colab_type":"code","colab":{}},"source":["def splitTrainTest(dict, n):\n","    train = {}\n","    train_v = []\n","    test_v = []\n","    test_a = []\n","\n","    for emot, vectors in dict.items():\n","        train[emot] = []\n","        for i, vector in enumerate(vectors):\n","            if i >= (len(vectors)-n):     # last n index to test\n","                test_v.append(vector)\n","                test_a.append(emot)\n","                continue\n","            train[emot].append(vector)\n","            train_v.append(vector)\n","    return train, train_v, test_v, test_a"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GyNqOaVkddCt","colab_type":"code","colab":{}},"source":["def findPriorProbability(dict):\n","    d = {}\n","    t_docs = len(vectorS)\n","    for emot, docs in dictionary.items():\n","        e_docs = len(docs)\n","        priP = e_docs / t_docs\n","        d[emot] = priP\n","    return d"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3H3bXlefeXU","colab_type":"code","colab":{}},"source":["def calculateMeanVar(dict, train_v):\n","    m = {}\n","    v = {}\n","    for emot, docs in dict.items():\n","        m[emot] = []\n","        v[emot] = []\n","        docs = np.array(docs)\n","        mean = np.mean(docs, axis=0)\n","        var = np.var(docs, axis=0) + (1e-9 * np.var(train_v, axis = 0).max())\n","        m[emot].append(mean)\n","        v[emot].append(var)\n","    return m, v"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uXZdq0GsnXW5","colab_type":"code","colab":{}},"source":["def pred(train, test_v, priorPrs, means, vars):\n","    preds = []\n","    for vector in test_v:\n","        vector = np.array(vector)\n","        posteriors = []\n","        emots = [*train]\n","        for emot in emots:\n","            prior = np.log(priorPrs[emot])\n","            mean = means[emot]\n","            std = vars[emot]\n","\n","            s = -(0.5 * np.sum(((vector - mean) ** 2) / std)) - (0.5 * np.sum(np.log(np.multiply((2 * np.pi), std))))\n","            posterior = prior + s\n","            posteriors.append(posterior)\n","        prdInx = np.argmax(posteriors)\n","        pred = emots[prdInx]\n","        preds.append(pred)\n","    return preds"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VHSkRldPeTrD","colab_type":"code","colab":{}},"source":["def NaiveBayes(dict, n):\n","    train = {}\n","    train_v = []\n","    test_v = []\n","    test_a = []\n","\n","    train, train_v, test_v, test_a = splitTrainTest(dict, n)\n","    print(\"Emotions:\", len(train), \"\\nTrain data:\", len(train_v), \"\\nNumber of prediction:\", len(test_v))\n","\n","    priorPrs = findPriorProbability(train)\n","    means, vars = calculateMeanVar(train, train_v)\n","\n","    predictions = []\n","    predictions = pred(train, test_v, priorPrs, means, vars)\n","    print(\"predictions:\",predictions)\n","    print(\"real:       \", test_a)\n","\n","    print(\"accuracy:\", accuracy_score(predictions, test_a))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GdiFdZqXe0OM","colab_type":"code","colab":{}},"source":["#print(len(dictionary)) # 3    -> # of emotions\n","#print(len(vectorS))    # 105  -> # of total docs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7-Bzh_KuuR5U","colab_type":"code","colab":{}},"source":["from sklearn.naive_bayes import GaussianNB\n","\n","def splitTrainTestforGaussianNB(dict, n):\n","    X_train = []\n","    y_train = []\n","    X_test = []\n","    y_test = []\n","\n","    for emot, vectors in dict.items():\n","        for i, vector in enumerate(vectors):\n","            if i >= len(vectors)-n:     # last index to test\n","                X_test.append(vector)\n","                y_test.append(emot)\n","                break\n","            X_train.append(vector)\n","            y_train.append(emot)\n","    return X_train, y_train, X_test, y_test"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vGVY4GGLqfZg","colab_type":"code","colab":{}},"source":["def sklearnGaussianNB(dict, n):\n","    X_train, y_train, X_test, y_test = splitTrainTestforGaussianNB(dictionary, n)\n","\n","    gnb = GaussianNB()\n","    y_pred = gnb.fit(X_train, y_train).predict(X_test)\n","    y_pred = np.array(y_pred).tolist()\n","\n","    print(accuracy_score(y_pred, y_test))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ifc6TaH14eVL","colab_type":"code","outputId":"9be83178-7f43-47e7-bf63-0cd81089d98d","executionInfo":{"status":"ok","timestamp":1589244355049,"user_tz":-180,"elapsed":21530,"user":{"displayName":"WhineyB","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_Vi2WUiksXxY70zz29ccNDzRabkMQHNJW4rgF0A=s64","userId":"14308996959334696623"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["NaiveBayes(dictionary, 5)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Emotions: 3 \n","Train data: 90 \n","Number of prediction: 15\n","predictions: ['3', '1', '3', '3', '3', '1', '1', '1', '1', '1', '3', '3', '1', '2', '2']\n","real:        ['3', '3', '3', '3', '3', '1', '1', '1', '1', '1', '2', '2', '2', '2', '2']\n","accuracy: 0.7333333333333333\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ixiW2mMlCZ44","colab_type":"code","outputId":"5016dc92-beac-4f03-b5db-166d0e94e97c","executionInfo":{"status":"ok","timestamp":1589244355050,"user_tz":-180,"elapsed":21521,"user":{"displayName":"WhineyB","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_Vi2WUiksXxY70zz29ccNDzRabkMQHNJW4rgF0A=s64","userId":"14308996959334696623"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["sklearnGaussianNB(dictionary, 5)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["0.6666666666666666\n"],"name":"stdout"}]}]}