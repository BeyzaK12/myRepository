{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Beyza_Kurt_NLP_final_part2_CENG3526.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1Voe7YT_PJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import re as re\n",
        "import zipfile as zipfile\n",
        "import math\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYaKz15qZonk",
        "colab_type": "code",
        "outputId": "b0c1a178-d97e-4b7e-eb5f-7ba04738d75b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN8iG5JYgzdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "commentsW = {}      # { (doc, emot): comment, ... }\n",
        "commentCounter = {}\n",
        "\n",
        "mytextzip = ''\n",
        "path = '/content/drive/My Drive/film_yorumlari.zip'\n",
        "\n",
        "emotions = {\n",
        "    \"1\": \"pozitif\",\n",
        "    \"2\": \"tarafsiz\",\n",
        "    \"3\": \"negatif\"\n",
        "}\n",
        "\n",
        "with zipfile.ZipFile(path) as z:\n",
        "    for zipinfo in z.infolist():\n",
        "        if zipinfo.filename.endswith('.txt') and re.search('raw_texts', zipinfo.filename):\n",
        "            with z.open(zipinfo) as f:\n",
        "                textfile = io.TextIOWrapper(f, encoding='cp1254', newline='')\n",
        "                for line in textfile:\n",
        "                    if len(line.strip()): mytextzip += line.strip()\n",
        "\n",
        "                filename = str(zipinfo.filename)\n",
        "                parts = filename.split(\"/\")\n",
        "                hash = parts[-2]\n",
        "                for key, emot in emotions.items():\n",
        "                    if hash == emot:\n",
        "                        hash = key\n",
        "                        break\n",
        "                parts = parts[-1].split(\".\")\n",
        "                doc = parts[0]\n",
        "                \n",
        "                commentsW[(doc, hash)] = mytextzip\n",
        "                if hash not in commentCounter:\n",
        "                    commentCounter[hash] = 0\n",
        "                commentCounter[hash] += 1\n",
        "                mytextzip = ''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aCNtmPBOMiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def splitTrainTest(dict, n):\n",
        "    train = {}      # { emot: [text1's (doc, emot) value, text2's (doc, emot) value,...], ... }\n",
        "    test_e = []     # [ 1. text's emot, ... ]\n",
        "    test_t = []     # [ 1. text's (doc, emot) value, ... ]\n",
        "\n",
        "    temp = {}       # to keep random index to selecting which texts will be test text\n",
        "    for emot, number in commentCounter.items():\n",
        "        temp[emot] = []\n",
        "        while len(temp[emot]) < n:\n",
        "            x = random.randint(0, number-1)\n",
        "            if x not in temp[emot]:\n",
        "                temp[emot].append(x)\n",
        "        temp[emot] = sorted(temp[emot])\n",
        "\n",
        "    # temp = {'3': [21, 33], '1': [13, 25], '2': [2, 25]}\n",
        "\n",
        "    for doc, emot in dict.keys():\n",
        "        if emot not in train:\n",
        "            train[emot] = []\n",
        "\n",
        "        if len(train[emot]) in temp[emot]:\n",
        "            temp[emot].remove(len(train[emot]))\n",
        "            for j, num in enumerate(temp[emot]):\n",
        "                temp[emot][j] -= 1\n",
        "            test_t.append((doc, emot))\n",
        "            test_e.append(emot)   # to prediction\n",
        "        else:\n",
        "            train[emot].append((doc, emot))\n",
        "\n",
        "    return train, test_e, test_t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSvdq9VZ3i1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test_e, test_t = splitTrainTest(commentsW, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYNrm1QQ4AVe",
        "colab_type": "code",
        "outputId": "7fd587f3-c263-4222-ccc9-0aa31de49703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "print(train)\n",
        "print(test_e)\n",
        "print(test_t[0])"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'3': [('1', '3'), ('10', '3'), ('11', '3'), ('12', '3'), ('14', '3'), ('16', '3'), ('17', '3'), ('18', '3'), ('19', '3'), ('2', '3'), ('20', '3'), ('21', '3'), ('22', '3'), ('24', '3'), ('25', '3'), ('26', '3'), ('27', '3'), ('28', '3'), ('29', '3'), ('3', '3'), ('30', '3'), ('31', '3'), ('32', '3'), ('33', '3'), ('34', '3'), ('35', '3'), ('4', '3'), ('6', '3'), ('7', '3'), ('8', '3'), ('9', '3')], '1': [('1', '1'), ('10', '1'), ('11', '1'), ('12', '1'), ('13', '1'), ('14', '1'), ('15', '1'), ('16', '1'), ('18', '1'), ('19', '1'), ('2', '1'), ('20', '1'), ('21', '1'), ('22', '1'), ('23', '1'), ('24', '1'), ('25', '1'), ('26', '1'), ('27', '1'), ('28', '1'), ('29', '1'), ('3', '1'), ('30', '1'), ('32', '1'), ('34', '1'), ('35', '1'), ('4', '1'), ('5', '1'), ('7', '1'), ('8', '1'), ('9', '1')], '2': [('10', '2'), ('11', '2'), ('12', '2'), ('13', '2'), ('14', '2'), ('15', '2'), ('16', '2'), ('17', '2'), ('18', '2'), ('19', '2'), ('2', '2'), ('20', '2'), ('21', '2'), ('22', '2'), ('24', '2'), ('25', '2'), ('26', '2'), ('27', '2'), ('28', '2'), ('29', '2'), ('3', '2'), ('30', '2'), ('31', '2'), ('32', '2'), ('33', '2'), ('34', '2'), ('35', '2'), ('4', '2'), ('6', '2'), ('8', '2'), ('9', '2')]}\n",
            "['3', '3', '3', '3', '1', '1', '1', '1', '2', '2', '2', '2']\n",
            "('13', '3')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmG1dNFRuo4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def splitIntoWords(text):\n",
        "    text = text.strip()\n",
        "\n",
        "    text = text.replace(\"(\",\"\")\n",
        "    text = text.replace(\")\",\"\")\n",
        "\n",
        "    text = text.replace(\"”\",'\"')\n",
        "    text = text.replace(',\"','\"')\n",
        "    text = text.replace(\",\", \"\")\n",
        "    text = text.replace(\"\\n\", \".\")\n",
        "    text = text.replace(\"  \", \" \")\n",
        "\n",
        "    text = re.split(r'\\W', text.lower())\n",
        "\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2vKv1Z0UO8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createDB(emot, docs, DB, n):\n",
        "\n",
        "    temp = []\n",
        "    for doc, emot in docs:\n",
        "        text = commentsW[(doc, emot)]\n",
        "        temp.append(splitIntoWords(text))\n",
        "\n",
        "    # DB = { emot1: { word1: [ 'word1's count in emot1 texts , {word2: 'word1 word2' pairs' count in emot1 texts, ...} ], ... }, ...}\n",
        "    # DB = { \"3\": { 'senaryo': [3, {'yazılmaz': 1, 'oyunculuk': 1, 'sorunu': 1}], ... }\n",
        "\n",
        "    DB[emot] = {}\n",
        "\n",
        "    for text in temp:\n",
        "        for i, word in enumerate(text):\n",
        "            if i == len(text)-n:\n",
        "                break\n",
        "            else:\n",
        "                for j in range(n-1):\n",
        "                    if j == 0:\n",
        "                        continue\n",
        "                    word += \" \" + text[i+j]\n",
        "\n",
        "                if word not in DB[emot]:\n",
        "                    DB[emot][word] = []\n",
        "                    DB[emot][word].append(0)\n",
        "                    DB[emot][word].append({})\n",
        "                \n",
        "                after = text[i+n-1]           # next word\n",
        "                DB[emot][word][0] += 1      # word1's count in text\n",
        "\n",
        "                # DB[emot][word][1]  dictionary contains words that come after word1 as key and their counts as value\n",
        "\n",
        "                if after not in DB[emot][word][1]:\n",
        "                    DB[emot][word][1][after] = 1\n",
        "                else:\n",
        "                    DB[emot][word][1][after] += 1\n",
        "\n",
        "    return DB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybWn72p3SGgb",
        "colab_type": "code",
        "outputId": "dc6835f5-cdc4-481f-8cf4-1f40f47f612c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Create DB\n",
        "\n",
        "n = int(input('Enter n: '))\n",
        "DB = {}\n",
        "for emot, docs in train.items():\n",
        "    DB = createDB(emot, docs, DB, n)\n",
        "\n",
        "# n = 2\n",
        "# print(DB[\"3\"])\n",
        "# {'senariste': [1, {'lafım': 1}], 'lafım': [2, {'rain': 1, 'filmin': 1}], 'rain': [2, {'man': 2}], ...}\n",
        "\n",
        "\n",
        "# n = 3\n",
        "# print(DB[\"3\"])\n",
        "# {'senariste lafım': [1, {'rain': 1}], 'lafım rain': [1, {'man': 1}], 'rain man': [2, {'filmini': 1,...}], ...}"
      ],
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter n: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_m1zkAgWe-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = []\n",
        "\n",
        "for doc, emot in test_t:\n",
        "    pr = {}     # to find best emotion prediction for text\n",
        "                # { emotion: prediction value, ... }  \n",
        "    \n",
        "    txt = commentsW[(doc, emot)]\n",
        "    words = splitIntoWords(txt)\n",
        "\n",
        "    for emot in train.keys():\n",
        "\n",
        "        pr[emot] = 0\n",
        "\n",
        "        for i, word in enumerate(words):\n",
        "            if i == len(words)-n:\n",
        "                break\n",
        "\n",
        "            for j in range(n-1):\n",
        "                if j == 0:\n",
        "                    continue\n",
        "                word += \" \" + words[i+j]\n",
        "\n",
        "            after = words[i+n-1]        # next word\n",
        "\n",
        "            if word in DB[emot]:\n",
        "                cTotal = DB[emot][word][0]             # of \"word\" in train text\n",
        "                if after in DB[emot][word][1]:\n",
        "                    cPart = DB[emot][word][1][after]   # of \"word after\" in train text\n",
        "\n",
        "                    p = cPart / cTotal      # prediction\n",
        "                else:\n",
        "                    p = 1e-10\n",
        "            else:\n",
        "                p = 1e-10\n",
        "\n",
        "            # to prevent errors;\n",
        "            # if one of words(word or after) not in emotion's texts,\n",
        "            # p will equal very small number\n",
        "\n",
        "            pr[emot] += math.log(p)\n",
        "            \n",
        "    # to find the best emotion prediction\n",
        "    pr = sorted(pr.items(), key=lambda pr: pr[1], reverse=True)\n",
        "    # pr[0][0] --> the best emotion\n",
        "    predictions.append(pr[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sbOIROGcrpK",
        "colab_type": "code",
        "outputId": "1bd9f445-7c29-41ed-fa14-b2327eb29f16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(predictions)"
      ],
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['3', '2', '3', '3', '1', '2', '1', '1', '1', '3', '2', '3']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Wza-Z9Ds5jE",
        "colab_type": "code",
        "outputId": "1e2f17f8-45aa-4d2d-abbd-b8505dbbcf15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "acc = 0\n",
        "for i in range(len(predictions)):\n",
        "    if predictions[i] == test_e[i]:\n",
        "        acc += 1\n",
        "\n",
        "print(acc, \"/\", len(predictions))\n",
        "print(\"accuracy:\", (acc / len(predictions)))\n",
        "\n",
        "# n = 2\n",
        "# 9 / 15    ---> accuracy: 0.6\n",
        "# 6 / 12    ---> accuracy: 0.5\n",
        "# 7 / 12    ---> accuracy: 0.58\n",
        "\n",
        "# n = 3\n",
        "# 5 / 15    ---> accuracy: 0.33\n",
        "# 6 / 12    ---> accuracy: 0.5\n",
        "# 7 / 12    ---> accuracy: 0.58"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7 / 12\n",
            "accuracy: 0.5833333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}