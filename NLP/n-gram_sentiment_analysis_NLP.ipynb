{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Beyza_Kurt_NLP_final_part2_CENG3526.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1Voe7YT_PJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io, os\n",
        "import re as re\n",
        "import zipfile as zipfile\n",
        "import math\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYaKz15qZonk",
        "colab_type": "code",
        "outputId": "9f2838d6-1ea9-42d0-aae4-39e2360eebe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN8iG5JYgzdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "commentsW = {}      # { (doc, emot): comment, ... }\n",
        "commentCounter = {}\n",
        "\n",
        "mytextzip = ''\n",
        "path = '/content/drive/My Drive/film_yorumlari.zip'\n",
        "\n",
        "emotions = {\n",
        "    \"1\": \"pozitif\",\n",
        "    \"2\": \"tarafsiz\",\n",
        "    \"3\": \"negatif\"\n",
        "}\n",
        "\n",
        "with zipfile.ZipFile(path) as z:\n",
        "    for zipinfo in z.infolist():\n",
        "        if zipinfo.filename.endswith('.txt') and re.search('raw_texts', zipinfo.filename):\n",
        "            with z.open(zipinfo) as f:\n",
        "                textfile = io.TextIOWrapper(f, encoding='cp1254', newline='')\n",
        "                for line in textfile:\n",
        "                    if len(line.strip()): mytextzip += line.strip()\n",
        "\n",
        "                filename = str(zipinfo.filename)\n",
        "                parts = filename.split(\"/\")\n",
        "                hash = parts[-2]\n",
        "                for key, emot in emotions.items():\n",
        "                    if hash == emot:\n",
        "                        hash = key\n",
        "                        break\n",
        "                parts = parts[-1].split(\".\")\n",
        "                doc = parts[0]\n",
        "                \n",
        "                commentsW[(doc, hash)] = mytextzip\n",
        "                if hash not in commentCounter:\n",
        "                    commentCounter[hash] = 0\n",
        "                commentCounter[hash] += 1\n",
        "                mytextzip = ''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aCNtmPBOMiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def splitTrainTest(dict, n):\n",
        "    train = {}      # { emot: [text1's (doc, emot) value, text2's (doc, emot) value,...], ... }\n",
        "    test_e = []     # [ 1. text's emot, ... ]\n",
        "    test_t = []     # [ 1. text's (doc, emot) value, ... ]\n",
        "\n",
        "    for doc, emot in dict.keys():\n",
        "        if emot not in train:\n",
        "            train[emot] = []\n",
        "\n",
        "        if len(train[emot]) >= commentCounter[emot]-n:\n",
        "            test_e.append(emot)\n",
        "            test_t.append((doc, emot))      # to prediction\n",
        "        else:\n",
        "            train[emot].append((doc, emot))\n",
        "\n",
        "    return train, test_e, test_t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSvdq9VZ3i1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test_e, test_t = splitTrainTest(commentsW, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYNrm1QQ4AVe",
        "colab_type": "code",
        "outputId": "85e43930-4ac9-4273-c2c9-b72929c3de83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "print(train)\n",
        "print(test_e)\n",
        "print(test_t[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'3': [('1', '3'), ('10', '3'), ('11', '3'), ('12', '3'), ('13', '3'), ('14', '3'), ('15', '3'), ('16', '3'), ('17', '3'), ('18', '3'), ('19', '3'), ('2', '3'), ('20', '3'), ('21', '3'), ('22', '3'), ('23', '3'), ('24', '3'), ('25', '3'), ('26', '3'), ('27', '3'), ('28', '3'), ('29', '3'), ('3', '3'), ('30', '3'), ('31', '3'), ('32', '3'), ('33', '3'), ('34', '3'), ('35', '3'), ('4', '3')], '1': [('1', '1'), ('10', '1'), ('11', '1'), ('12', '1'), ('13', '1'), ('14', '1'), ('15', '1'), ('16', '1'), ('17', '1'), ('18', '1'), ('19', '1'), ('2', '1'), ('20', '1'), ('21', '1'), ('22', '1'), ('23', '1'), ('24', '1'), ('25', '1'), ('26', '1'), ('27', '1'), ('28', '1'), ('29', '1'), ('3', '1'), ('30', '1'), ('31', '1'), ('32', '1'), ('33', '1'), ('34', '1'), ('35', '1'), ('4', '1')], '2': [('1', '2'), ('10', '2'), ('11', '2'), ('12', '2'), ('13', '2'), ('14', '2'), ('15', '2'), ('16', '2'), ('17', '2'), ('18', '2'), ('19', '2'), ('2', '2'), ('20', '2'), ('21', '2'), ('22', '2'), ('23', '2'), ('24', '2'), ('25', '2'), ('26', '2'), ('27', '2'), ('28', '2'), ('29', '2'), ('3', '2'), ('30', '2'), ('31', '2'), ('32', '2'), ('33', '2'), ('34', '2'), ('35', '2'), ('4', '2')]}\n",
            "['3', '3', '3', '3', '3', '1', '1', '1', '1', '1', '2', '2', '2', '2', '2']\n",
            "('5', '3')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmG1dNFRuo4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def splitIntoWords(text):\n",
        "    text = text.strip()\n",
        "\n",
        "    text = text.replace(\"(\",\"\")\n",
        "    text = text.replace(\")\",\"\")\n",
        "\n",
        "    text = text.replace(\"”\",'\"')\n",
        "    text = text.replace(',\"','\"')\n",
        "    text = text.replace(\",\", \"\")\n",
        "    text = text.replace(\"\\n\", \".\")\n",
        "    text = text.replace(\"  \", \" \")\n",
        "\n",
        "    text = re.split(r'\\W', text.lower())\n",
        "\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2vKv1Z0UO8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createDB(emot, docs, DB, n):\n",
        "\n",
        "    temp = []\n",
        "    for doc, emot in docs:\n",
        "        text = commentsW[(doc, emot)]\n",
        "        temp.append(splitIntoWords(text))\n",
        "\n",
        "    # DB = { emot1: { word1: [ 'word1's count in emot1 texts , {word2: 'word1 word2' pairs' count in emot1 texts, ...} ], ... }, ...}\n",
        "    # DB = { \"3\": { 'senaryo': [3, {'yazılmaz': 1, 'oyunculuk': 1, 'sorunu': 1}], ... }\n",
        "\n",
        "    DB[emot] = {}\n",
        "\n",
        "    for text in temp:\n",
        "        for i, word in enumerate(text):\n",
        "            if i == len(text)-n:\n",
        "                break\n",
        "            else:\n",
        "                for j in range(n-1):\n",
        "                    if j == 0:\n",
        "                        continue\n",
        "                    word += \" \" + text[i+j]\n",
        "\n",
        "                if word not in DB[emot]:\n",
        "                    DB[emot][word] = []\n",
        "                    DB[emot][word].append(0)\n",
        "                    DB[emot][word].append({})\n",
        "                \n",
        "                after = text[i+n-1]           # next word\n",
        "                DB[emot][word][0] += 1      # word1's count in text\n",
        "\n",
        "                # DB[emot][word][1]  dictionary contains words that come after word1 as key and their counts as value\n",
        "\n",
        "                if after not in DB[emot][word][1]:\n",
        "                    DB[emot][word][1][after] = 1\n",
        "                else:\n",
        "                    DB[emot][word][1][after] += 1\n",
        "\n",
        "    return DB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybWn72p3SGgb",
        "colab_type": "code",
        "outputId": "114fefe9-6967-46ec-f121-01f88f8722b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Create DB\n",
        "\n",
        "n = int(input('Enter n: '))\n",
        "DB = {}\n",
        "for emot, docs in train.items():\n",
        "    DB = createDB(emot, docs, DB, n)\n",
        "\n",
        "# n = 2\n",
        "# print(DB[\"3\"])\n",
        "# {'senariste': [1, {'lafım': 1}], 'lafım': [2, {'rain': 1, 'filmin': 1}], 'rain': [2, {'man': 2}], ...}\n",
        "\n",
        "\n",
        "# n = 3\n",
        "# print(DB[\"3\"])\n",
        "# {'senariste lafım': [1, {'rain': 1}], 'lafım rain': [1, {'man': 1}], 'rain man': [2, {'filmini': 1,...}], ...}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter n: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_m1zkAgWe-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = []\n",
        "\n",
        "for doc, emot in test_t:\n",
        "    pr = {}     # to find best emotion prediction for text\n",
        "                # { emotion: prediction value, ... }  \n",
        "    \n",
        "    txt = commentsW[(doc, emot)]\n",
        "    words = splitIntoWords(txt)\n",
        "\n",
        "    for emot in train.keys():\n",
        "\n",
        "        pr[emot] = 0\n",
        "\n",
        "        for i, word in enumerate(words):\n",
        "            if i == len(words)-n:\n",
        "                break\n",
        "\n",
        "            for j in range(n-1):\n",
        "                if j == 0:\n",
        "                    continue\n",
        "                word += \" \" + words[i+j]\n",
        "\n",
        "            after = words[i+n-1]        # next word\n",
        "\n",
        "            if word in DB[emot]:\n",
        "                cTotal = DB[emot][word][0]             # of \"word\" in train text\n",
        "                if after in DB[emot][word][1]:\n",
        "                    cPart = DB[emot][word][1][after]   # of \"word after\" in train text\n",
        "\n",
        "                    p = cPart / cTotal      # prediction\n",
        "                else:\n",
        "                    p = 1e-10\n",
        "            else:\n",
        "                p = 1e-10\n",
        "\n",
        "            # to prevent errors;\n",
        "            # if one of words(word or after) not in emotion's texts,\n",
        "            # p will equal very small number\n",
        "\n",
        "            pr[emot] += math.log(p)\n",
        "            \n",
        "    # to find the best emotion prediction\n",
        "    pr = sorted(pr.items(), key=lambda pr: pr[1], reverse=True)\n",
        "    # pr[0][0] --> the best emotion\n",
        "    predictions.append(pr[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sbOIROGcrpK",
        "colab_type": "code",
        "outputId": "227adfc8-841d-4e15-9935-edf1d537141d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(predictions)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['3', '3', '1', '3', '2', '1', '1', '1', '1', '3', '2', '1', '3', '2', '3']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Wza-Z9Ds5jE",
        "colab_type": "code",
        "outputId": "ba7b7835-3f0a-4133-9703-6c66d82d8c01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "acc = 0\n",
        "for i in range(len(predictions)):\n",
        "    if predictions[i] == test_e[i]:\n",
        "        acc += 1\n",
        "\n",
        "print(acc, \"/\", len(predictions))\n",
        "print(\"accuracy:\", (acc / len(predictions)))\n",
        "\n",
        "# n = 2\n",
        "# 9 / 15\n",
        "# accuracy: 0.6\n",
        "\n",
        "# n = 3\n",
        "# 5 / 15\n",
        "# accuracy: 0.33"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9 / 15\n",
            "accuracy: 0.6\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}